//package com.iven.musicplayergo
package com.iven.musicplayergo

import android.content.Context
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.util.Log
import com.iflytek.sparkchain.core.SparkChain
import com.iflytek.sparkchain.core.SparkChainConfig
import com.iflytek.sparkchain.core.asr.ASR
import com.iflytek.sparkchain.core.asr.AsrCallbacks
import com.iven.musicplayergo.models.ChatMessage
import com.iven.musicplayergo.utils.BluetoothScoHelper
import com.iven.musicplayergo.wakeup.LogOutputHelper

object VoiceRecognizer {

    private const val TAG = "VoiceRecognizer"
    private lateinit var mAsr: ASR
    private var isInitialized = false
    private var onRecognizeCallback: ((String) -> Unit)? = null

    class MyAsrCallbacks(private val onResult: (String) -> Unit) : AsrCallbacks {
        override fun onResult(result: ASR.ASRResult?, usrTag: Any?) {
            val text = result?.bestMatchText ?: ""
            Log.i(TAG, "[onResult] ğŸ¤ è¯†åˆ«ç»“æœï¼š$text")
            onResult(text)
        }
        override fun onError(error: ASR.ASRError?, usrTag: Any?) {
            Log.e(TAG, "[onError] âŒ è¯†åˆ«å¤±è´¥ï¼š${error?.code}")
        }
        override fun onBeginOfSpeech() {
            Log.i(TAG, "[onBeginOfSpeech] ğŸ—£ï¸ å¼€å§‹è¯´è¯")
        }
        override fun onEndOfSpeech() {
            Log.i(TAG, "[onEndOfSpeech] ğŸ›‘ è¯´è¯ç»“æŸ")
        }
    }

    fun init(context: Context) {
        if (isInitialized) return
        mAsr = ASR("zh_cn", "iat", "mandarin")
        mAsr.vinfo(true)
        mAsr.registerCallbacks(object : AsrCallbacks {
            override fun onResult(result: ASR.ASRResult?, usrTag: Any?) {
                val text = result?.bestMatchText ?: ""
                Log.i(TAG, "[VoiceRecognizer][speedtotext] ğŸ¤ è¯†åˆ«ç»“æœï¼š$text")
                onRecognizeCallback?.invoke(text)
            }
            override fun onError(error: ASR.ASRError?, usrTag: Any?) {
                Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ è¯†åˆ«å¤±è´¥ï¼š${error?.code}")
            }
            override fun onBeginOfSpeech() {
                Log.i(TAG, "[VoiceRecognizer][speedtotext] ğŸ—£ï¸ å¼€å§‹è¯´è¯")
            }
            override fun onEndOfSpeech() {
                Log.i(TAG, "[VoiceRecognizer][speedtotext] ğŸ›‘ ç»“æŸè¯´è¯")
            }
        })
        isInitialized = true
        Log.i(TAG, "[VoiceRecognizer][init] âœ… åˆå§‹åŒ–å®Œæˆ")
    }

    fun startRecognize(context: Context, callback: (String) -> Unit) {
        if (!isInitialized) {
            Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ æœªåˆå§‹åŒ–ï¼Œè‡ªåŠ¨è°ƒç”¨ init()")
            init(context)
        }
        onRecognizeCallback = callback
        val tag = System.currentTimeMillis().toString()
        val ret = mAsr.start(tag)
        if (ret != 0) {
            Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ å¯åŠ¨å¤±è´¥ï¼Œret=$ret")
            return
        }
        LogOutputHelper.print("â–¶ å¯åŠ¨è¯­éŸ³è¯†åˆ«", ChatMessage.Sender.BOT)
        startAudioCaptureAndFeed(context)
    }

    private fun startAudioCaptureAndFeed(context: Context) {
        Thread {
            try {
                val sampleRate = 16000
                val channelConfig = AudioFormat.CHANNEL_IN_MONO
                val audioFormat = AudioFormat.ENCODING_PCM_16BIT
                val minBufSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat)

                val preferredSources = listOf(
                    MediaRecorder.AudioSource.VOICE_RECOGNITION,
                    MediaRecorder.AudioSource.VOICE_COMMUNICATION,
                    MediaRecorder.AudioSource.MIC
                )

                var audioRecord: AudioRecord? = null
                for (source in preferredSources) {
                    val ar = AudioRecord(source, sampleRate, channelConfig, audioFormat, minBufSize)
                    if (ar.state == AudioRecord.STATE_INITIALIZED) {
                        LogOutputHelper.print("âœ… ä½¿ç”¨éŸ³æº $source åˆå§‹åŒ–æˆåŠŸ", ChatMessage.Sender.BOT)
                        Log.i("speedtotext", "âœ… ä½¿ç”¨éŸ³æº $source åˆå§‹åŒ–æˆåŠŸ")
                        audioRecord = ar
                        break
                    } else {
                        LogOutputHelper.print("âŒ éŸ³æº $source åˆå§‹åŒ–å¤±è´¥", ChatMessage.Sender.BOT)
                    }
                }

                if (audioRecord == null) {
                    LogOutputHelper.print("âŒ æ‰€æœ‰éŸ³æºåˆå§‹åŒ–å¤±è´¥ï¼Œç»ˆæ­¢è¯†åˆ«", ChatMessage.Sender.BOT)
                    return@Thread
                }

                audioRecord.startRecording()
                LogOutputHelper.print("ğŸ™ï¸ å¼€å§‹å½•éŸ³", ChatMessage.Sender.BOT)

                val buffer = ByteArray(minBufSize)
                val startTime = System.currentTimeMillis()
                while (System.currentTimeMillis() - startTime < 5000) {
                    val len = audioRecord.read(buffer, 0, buffer.size)
                    if (len > 0) {
                        val data = buffer.copyOf(len)
                        mAsr.write(data)
                    }
                }

                audioRecord.stop()
                audioRecord.release()
                LogOutputHelper.print("ğŸ›‘ åœæ­¢å½•éŸ³", ChatMessage.Sender.BOT)
                mAsr.stop(true)
                LogOutputHelper.print("â¹ï¸ åœæ­¢è¯†åˆ«", ChatMessage.Sender.BOT)

            } catch (e: SecurityException) {
                Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ ç¼ºå°‘å½•éŸ³æƒé™", e)
            } catch (e: Exception) {
                Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ å½•éŸ³å¼‚å¸¸", e)
            }
        }.start()
    }
}

//package com.iven.musicplayergo
package com.iven.musicplayergo

import android.content.Context
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.util.Log
import com.iflytek.sparkchain.core.SparkChain
import com.iflytek.sparkchain.core.SparkChainConfig
import com.iflytek.sparkchain.core.asr.ASR
import com.iflytek.sparkchain.core.asr.AsrCallbacks
import com.iven.musicplayergo.models.ChatMessage
import com.iven.musicplayergo.utils.BluetoothScoHelper
import com.iven.musicplayergo.wakeup.LogOutputHelper

object VoiceRecognizer {

    private const val TAG = "VoiceRecognizer"
    private lateinit var mAsr: ASR
    private var isInitialized = false
    private var onRecognizeCallback: ((String) -> Unit)? = null

    class MyAsrCallbacks(private val onResult: (String) -> Unit) : AsrCallbacks {
        override fun onResult(result: ASR.ASRResult?, usrTag: Any?) {
            val text = result?.bestMatchText ?: ""
            Log.i(TAG, "[onResult] ğŸ¤ è¯†åˆ«ç»“æœï¼š$text")
            onResult(text)
        }
        override fun onError(error: ASR.ASRError?, usrTag: Any?) {
            Log.e(TAG, "[onError] âŒ è¯†åˆ«å¤±è´¥ï¼š${error?.code}")
        }
        override fun onBeginOfSpeech() {
            Log.i(TAG, "[onBeginOfSpeech] ğŸ—£ï¸ å¼€å§‹è¯´è¯")
        }
        override fun onEndOfSpeech() {
            Log.i(TAG, "[onEndOfSpeech] ğŸ›‘ è¯´è¯ç»“æŸ")
        }
    }

    fun init(context: Context) {
        if (isInitialized) return
        mAsr = ASR("zh_cn", "iat", "mandarin")
        mAsr.vinfo(true)
        mAsr.registerCallbacks(object : AsrCallbacks {
            override fun onResult(result: ASR.ASRResult?, usrTag: Any?) {
                val text = result?.bestMatchText ?: ""
                Log.i(TAG, "[VoiceRecognizer][speedtotext] ğŸ¤ è¯†åˆ«ç»“æœï¼š$text")
                onRecognizeCallback?.invoke(text)
            }
            override fun onError(error: ASR.ASRError?, usrTag: Any?) {
                Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ è¯†åˆ«å¤±è´¥ï¼š${error?.code}")
            }
            override fun onBeginOfSpeech() {
                Log.i(TAG, "[VoiceRecognizer][speedtotext] ğŸ—£ï¸ å¼€å§‹è¯´è¯")
            }
            override fun onEndOfSpeech() {
                Log.i(TAG, "[VoiceRecognizer][speedtotext] ğŸ›‘ ç»“æŸè¯´è¯")
            }
        })
        isInitialized = true
        Log.i(TAG, "[VoiceRecognizer][init] âœ… åˆå§‹åŒ–å®Œæˆ")
    }

    fun startRecognize(context: Context, callback: (String) -> Unit) {
        if (!isInitialized) {
            Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ æœªåˆå§‹åŒ–ï¼Œè‡ªåŠ¨è°ƒç”¨ init()")
            init(context)
        }
        onRecognizeCallback = callback
        val tag = System.currentTimeMillis().toString()
        val ret = mAsr.start(tag)
        if (ret != 0) {
            Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ å¯åŠ¨å¤±è´¥ï¼Œret=$ret")
            return
        }
        LogOutputHelper.print("â–¶ å¯åŠ¨è¯­éŸ³è¯†åˆ«", ChatMessage.Sender.BOT)
        startAudioCaptureAndFeed(context)
    }

    private fun startAudioCaptureAndFeed(context: Context) {
        Thread {
            try {
                val sampleRate = 16000
                val channelConfig = AudioFormat.CHANNEL_IN_MONO
                val audioFormat = AudioFormat.ENCODING_PCM_16BIT
                val minBufSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat)

                val preferredSources = listOf(
                    MediaRecorder.AudioSource.VOICE_RECOGNITION,
                    MediaRecorder.AudioSource.VOICE_COMMUNICATION,
                    MediaRecorder.AudioSource.MIC
                )

                var audioRecord: AudioRecord? = null
                for (source in preferredSources) {
                    val ar = AudioRecord(source, sampleRate, channelConfig, audioFormat, minBufSize)
                    if (ar.state == AudioRecord.STATE_INITIALIZED) {
                        LogOutputHelper.print("âœ… ä½¿ç”¨éŸ³æº $source åˆå§‹åŒ–æˆåŠŸ", ChatMessage.Sender.BOT)
                        audioRecord = ar
                        break
                    } else {
                        LogOutputHelper.print("âŒ éŸ³æº $source åˆå§‹åŒ–å¤±è´¥", ChatMessage.Sender.BOT)
                    }
                }

                if (audioRecord == null) {
                    LogOutputHelper.print("âŒ æ‰€æœ‰éŸ³æºåˆå§‹åŒ–å¤±è´¥ï¼Œç»ˆæ­¢è¯†åˆ«", ChatMessage.Sender.BOT)
                    return@Thread
                }

                audioRecord.startRecording()
                LogOutputHelper.print("ğŸ™ï¸ å¼€å§‹å½•éŸ³", ChatMessage.Sender.BOT)

                val buffer = ByteArray(minBufSize)
                val startTime = System.currentTimeMillis()
                while (System.currentTimeMillis() - startTime < 5000) {
                    val len = audioRecord.read(buffer, 0, buffer.size)
                    if (len > 0) {
                        val data = buffer.copyOf(len)
                        mAsr.write(data)
                    }
                }

                audioRecord.stop()
                audioRecord.release()
                LogOutputHelper.print("ğŸ›‘ åœæ­¢å½•éŸ³", ChatMessage.Sender.BOT)
                mAsr.stop(true)
                LogOutputHelper.print("â¹ï¸ åœæ­¢è¯†åˆ«", ChatMessage.Sender.BOT)

            } catch (e: SecurityException) {
                Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ ç¼ºå°‘å½•éŸ³æƒé™", e)
            } catch (e: Exception) {
                Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ å½•éŸ³å¼‚å¸¸", e)
            }
        }.start()
    }
}
//import android.content.Context
//import android.media.AudioFormat
//import android.media.AudioRecord
//import android.media.MediaRecorder
//import android.util.Log
//import com.iflytek.sparkchain.core.SparkChain
//import com.iflytek.sparkchain.core.SparkChainConfig
//import com.iflytek.sparkchain.core.asr.ASR
//import com.iflytek.sparkchain.core.asr.AsrCallbacks
//import com.iven.musicplayergo.models.ChatMessage
//import com.iven.musicplayergo.wakeup.LogOutputHelper
//
//object VoiceRecognizer {
//
//    private const val TAG = "VoiceRecognizer"
//    private lateinit var mAsr: ASR
//    private var isInitialized = false
//
//    class MyAsrCallbacks(private val onResult: (String) -> Unit) : AsrCallbacks {
//
//        override fun onResult(result: ASR.ASRResult?, usrTag: Any?) {
//            val text = result?.bestMatchText ?: ""
//            Log.i("VoiceRecognizer", "[onResult] ğŸ¤ è¯†åˆ«ç»“æœï¼š$text")
//            onResult(text)
//        }
//
//        override fun onError(error: ASR.ASRError?, usrTag: Any?) {
//            Log.e("VoiceRecognizer", "[onError] âŒ è¯†åˆ«å¤±è´¥ï¼š${error?.code}")
//        }
//
//        override fun onBeginOfSpeech() {
//            Log.i("VoiceRecognizer", "[onBeginOfSpeech] ğŸ—£ï¸ å¼€å§‹è¯´è¯")
//        }
//
//        override fun onEndOfSpeech() {
//            Log.i("VoiceRecognizer", "[onEndOfSpeech] ğŸ›‘ è¯´è¯ç»“æŸ")
//        }
//    }
//    /** åˆå§‹åŒ– ASR å¼•æ“ */
//    fun init(context: Context) {
//        if (isInitialized) return
//
//        // âœ… å®˜æ–¹æ¨èåˆå§‹åŒ–æ–¹å¼ï¼ˆæ„é€ å™¨ï¼‰
//        mAsr = ASR("zh_cn", "iat", "mandarin")
//        mAsr.vinfo(true)
//
//        // âœ… æ³¨å†Œè¯†åˆ«å›è°ƒ
//        mAsr.registerCallbacks(object : AsrCallbacks {
//            override fun onResult(result: ASR.ASRResult?, usrTag: Any?) {
//                val text = result?.bestMatchText ?: ""
//                Log.i(TAG, "[VoiceRecognizer][speedtotext] ğŸ¤ è¯†åˆ«ç»“æœï¼š$text")
//                onRecognizeCallback?.invoke(text)
//            }
//
//            override fun onError(error: ASR.ASRError?, usrTag: Any?) {
//                Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ è¯†åˆ«å¤±è´¥ï¼š${error?.code}")
//            }
//
//            override fun onBeginOfSpeech() {
//                Log.i(TAG, "[VoiceRecognizer][speedtotext] ğŸ—£ï¸ å¼€å§‹è¯´è¯")
//            }
//
//            override fun onEndOfSpeech() {
//                Log.i(TAG, "[VoiceRecognizer][speedtotext] ğŸ›‘ ç»“æŸè¯´è¯")
//            }
//        })
//
//        isInitialized = true
//        Log.i(TAG, "[VoiceRecognizer][init] âœ… åˆå§‹åŒ–å®Œæˆï¼ˆæ„é€ å™¨æ–¹å¼ï¼‰")
//    }
//    private var onRecognizeCallback: ((String) -> Unit)? = null
//
//    /** å¼€å§‹è¯†åˆ«ï¼ˆå¯åŠ¨åå†…éƒ¨è°ƒç”¨ start + audio + stopï¼‰ */
//    fun startRecognize(context: Context, callback: (String) -> Unit) {
//        if (!isInitialized) {
//            Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ æœªåˆå§‹åŒ–ï¼Œè‡ªåŠ¨è°ƒç”¨ init()")
//            init(context ?: return) // å‡è®¾ä½ å­˜å‚¨äº† context
//        }
//
//        onRecognizeCallback = callback
//        val tag = System.currentTimeMillis().toString()
//        val ret = mAsr.start(tag)
//        if (ret != 0) {
//            Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ å¯åŠ¨å¤±è´¥ï¼Œret=$ret")
//            return
//        }
//
////        Log.i(TAG, "[VoiceRecognizer][speedtotext] â–¶ å¯åŠ¨è¯†åˆ«")
////        LogOutputHelper.print("å¯åŠ¨è¯†åˆ«", ChatMessage.Sender.BOT)
////        LogOutputHelper.print("ğŸ¤– å¯åŠ¨è¯†åˆ«")
//
//
//        // å¯ç”¨ AudioRecord é‡‡é›†å¹¶å†™å…¥ï¼š
//        startAudioCaptureAndFeed(context)
//    }
//
//    /** ç¤ºä¾‹ï¼šç®€åŒ–å¤„ç†éŸ³é¢‘é‡‡é›†å¹¶ feed åˆ° ASR */
//    private fun startAudioCaptureAndFeed(context: Context) {
//        Thread {
//            try {
//                val sampleRate = 16000
//                val channelConfig = AudioFormat.CHANNEL_IN_MONO
//                val audioFormat = AudioFormat.ENCODING_PCM_16BIT
//                val minBufSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat)
//                val audioRecord = AudioRecord(
//                    MediaRecorder.AudioSource.MIC,
//                    sampleRate,
//                    channelConfig,
//                    audioFormat,
//                    minBufSize
//                )
//
//                // âœ… æƒé™æ£€æŸ¥å»ºè®®åœ¨è°ƒç”¨ startRecognize() æ—¶å¤„ç†
//                if (audioRecord.state != AudioRecord.STATE_INITIALIZED) {
//                    Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ AudioRecord åˆå§‹åŒ–å¤±è´¥")
//                    return@Thread
//                }
//
//                val buffer = ByteArray(minBufSize)
//                audioRecord.startRecording()
//                Log.i(TAG, "[VoiceRecognizer][speedtotext] ğŸ™ï¸ å¼€å§‹å½•éŸ³")
//                LogOutputHelper.print("ğŸ™ï¸ æœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„", ChatMessage.Sender.BOT)
//
//                val startTime = System.currentTimeMillis()
//                while (System.currentTimeMillis() - startTime < 5000) { // é‡‡é›† 5 ç§’éŸ³é¢‘
//                    val len = audioRecord.read(buffer, 0, buffer.size)
//                    if (len > 0) {
//                        val data = buffer.copyOf(len)
//                        mAsr.write(data)
//                    }
//                }
//
//                audioRecord.stop()
//                audioRecord.release()
//                Log.i(TAG, "[VoiceRecognizer][speedtotext] ğŸ›‘ åœæ­¢å½•éŸ³")
////                LogOutputHelper.print("ğŸ›‘ åœæ­¢å½•éŸ³")
//
//                mAsr.stop(true)
//                Log.i(TAG, "[VoiceRecognizer][speedtotext] â¹ï¸ åœæ­¢è¯†åˆ«")
////                LogOutputHelper.print("â¹ï¸ åœæ­¢è¯†åˆ«")
//
//
//            } catch (e: SecurityException) {
//                Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ ç¼ºå°‘å½•éŸ³æƒé™", e)
//            } catch (e: Exception) {
//                Log.e(TAG, "[VoiceRecognizer][speedtotext] âŒ å½•éŸ³å¼‚å¸¸", e)
//            }
//        }.start()
//    }
//}
